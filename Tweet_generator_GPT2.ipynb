{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet_generator_GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salujarohit/AI-Generated-Text-Powered-by-GPT2/blob/main/Tweet_generator_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqChI-B4qWG7",
        "outputId": "9b5a967f-702f-4c97-89de-b2f991512a68"
      },
      "source": [
        "!pip3 install gpt-2-simple\n",
        "!pip install tensorflow==1.14\n",
        "!pip install tensorflow-gpu==1.14.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.18.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=0a3bbc40be7ec1776f309db82bce45012dfd30ad348bee49ece11d73d33a732e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n",
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.33.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (50.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pso_jadginhk",
        "outputId": "2b8cd6ee-48cd-486f-e064-43d9c472f78e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec  2 02:46:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATXeCGmdjwy1"
      },
      "source": [
        "#imports\n",
        "import gpt_2_simple as gpt2\n",
        "import os \n",
        "import requests\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3tplFsi73q"
      },
      "source": [
        "# Downloading GPT2 - pretained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9qkpUEWzJiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9ad914-942f-4eb4-95fc-efd85fcdc9ef"
      },
      "source": [
        "model_name = \"355M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "\tprint(f\"Downloading {model_name} model...\")\n",
        "\tgpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 385Mit/s]                                                      "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading 355M model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fetching encoder.json: 1.05Mit [00:00, 40.5Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 905Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:22, 62.0Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 216Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 84.6Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 132Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N1icp17sdB2",
        "outputId": "4d4d0bed-c52b-482b-f19c-1171f16b0641"
      },
      "source": [
        "file_name = \"joined_tweets-3.csv\"\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )\n",
        "\n",
        "#gpt2.generate(sess)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 25.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 405144 tokens\n",
            "Training...\n",
            "[10 | 17.67] loss=2.35 avg=2.35\n",
            "[20 | 26.29] loss=2.71 avg=2.53\n",
            "[30 | 34.92] loss=2.42 avg=2.49\n",
            "[40 | 43.54] loss=2.35 avg=2.46\n",
            "[50 | 52.16] loss=2.03 avg=2.37\n",
            "[60 | 60.79] loss=1.94 avg=2.30\n",
            "[70 | 69.41] loss=1.98 avg=2.25\n",
            "[80 | 78.03] loss=2.15 avg=2.24\n",
            "[90 | 86.65] loss=2.48 avg=2.27\n",
            "[100 | 95.28] loss=2.27 avg=2.27\n",
            "[110 | 103.90] loss=1.74 avg=2.22\n",
            "[120 | 112.52] loss=2.51 avg=2.24\n",
            "[130 | 121.15] loss=2.07 avg=2.23\n",
            "[140 | 129.77] loss=2.13 avg=2.22\n",
            "[150 | 138.39] loss=1.98 avg=2.20\n",
            "[160 | 147.00] loss=2.12 avg=2.20\n",
            "[170 | 155.62] loss=1.65 avg=2.16\n",
            "[180 | 164.25] loss=1.89 avg=2.15\n",
            "[190 | 172.86] loss=1.08 avg=2.08\n",
            "[200 | 181.48] loss=2.09 avg=2.08\n",
            "======== SAMPLE 1 ========\n",
            " doesn't mean they won't. But they have an incredibly high success rate. People get into Harvard a whole lot more successful people than successful people get into Harvard a whole lot less successful. It's an incredible skill set.\"\n",
            " < | startoftext |>The number one thing that separates the truly successful from average: how smart they are.And that's one way we can make smart more than normal.\"I think the real talent of most young college graduates is not IQ but something else: They are super prepared now to run a world leader.\" –Tim Cook<|endoftext|>\n",
            "<|startoftext |>When will there be the opportunity for people not to work so much as do all of the work that they think they do?- Tim Cook<|endoftext|>\n",
            "<|startoftext |>If you have to take a vacation, make it quick<|endoftext|>\n",
            "<|startoftext |>A new Harvard MBA interview is taking place.It's great. It's a great time in Boston.<|endoftext|>\n",
            "<|startoftext |>There's a whole new category of person for whom success doesn't matter that's taking over the top job in Wall Street.<|endoftext|>\n",
            "<|startoftext |>I'm reading The Art of War so i might as well ask some questions about it. I'm writing a very light essay about my experience.<|endoftext|>\n",
            "<|startoftext |>What an epic fail our economy is making of managing expectations and growth.<|endoftext|>\n",
            "<|startoftext |>It's hard to argue that investing in a company with 100%+ shareholder ownership should be a good investment.I wrote a pretty good piece<|endoftext|>\n",
            "<|startoftext |>The only reason why people are so cheap and greedy at the same time is that the same companies can sell you a crappy product at a high margin.<|endoftext|>\n",
            "<|startoftext |>That said, I hope the next year is a success.I'm excited about all the cool things we can accomplish.This one was hard.<|endoftext|>\n",
            "<|startoftext |>One more thing: we have to pay a living wage.<|endoftext|>\n",
            "<|startoftext |>I am reading Twilight by Robert Anson on Amazon - amazing book.I'm really digging how insightful this is.<|endoftext|>\n",
            "<|startoftext |>We can't stop there. It's hard to have a good time when money starts the conversation. <|endoftext|>\n",
            "<|startoftext |>We could do this without debt<|endoftext|>\n",
            "<|startoftext |>If not<|endoftext|>\n",
            "<|startoftext |>The real value of any good is exactly what it cannot do.It's that unique ability to adapt to change.<|endoftext|>\n",
            "<|startoftext |>If you believe in good leadership<|endoftext|>\n",
            "<|startoftext |>This is an important article: \"How do you keep your boss on side? <|endoftext|>\n",
            "<|startoftext |>The best leadership story doesn't even have a leader. It starts with good values and ends with good results.\" - Steve Jobs<|endoftext|>\n",
            "<|startoftext |>The truth is that only 1 in 6 leaders can lead a company to profitability.<|endoftext|>\n",
            "<|startoftext |>I'm very excited to announce we are offering a live online version of the book.Please join me and subscribe if you want us to make it live again.<|endoftext|>\n",
            "<|startoftext |>I used to work hard and play hard. But since I stopped working and became an entrepreneur I've become a super lucky guy.<|endoftext|>\n",
            "<|startoftext |>We are in a race to the bottom. #Hustle<|endoftext|>\n",
            "<|startoftext |>The number one way to succeed at any job: Get a ton of free time. So far it's working for everyone.And it's awesome.\" -BenDolia<|endoftext|>\n",
            "<|startoftext |>Don't be a lazy beta rat.You'll regret it later.<|endoftext|>\n",
            "<|startoftext |>Thank you for saying something so cool <|endoftext|>\n",
            "<|startoftext |>What is it about leadership that a huge number of people are so easily swayed by the \"best leader ever\", yet have no clue what to follow/follows when someone better says hello.<|endoftext|\n",
            "\n",
            "[210 | 213.36] loss=1.85 avg=2.07\n",
            "[220 | 221.98] loss=2.03 avg=2.07\n",
            "[230 | 230.60] loss=1.75 avg=2.06\n",
            "[240 | 239.23] loss=1.76 avg=2.04\n",
            "[250 | 247.87] loss=2.07 avg=2.04\n",
            "[260 | 256.49] loss=1.50 avg=2.02\n",
            "[270 | 265.12] loss=2.47 avg=2.04\n",
            "[280 | 273.74] loss=1.74 avg=2.03\n",
            "[290 | 282.35] loss=1.91 avg=2.02\n",
            "[300 | 290.97] loss=2.07 avg=2.02\n",
            "[310 | 299.58] loss=2.01 avg=2.02\n",
            "[320 | 308.23] loss=1.36 avg=2.00\n",
            "[330 | 316.88] loss=1.18 avg=1.97\n",
            "[340 | 325.50] loss=2.53 avg=1.99\n",
            "[350 | 334.12] loss=2.24 avg=2.00\n",
            "[360 | 342.74] loss=2.31 avg=2.01\n",
            "[370 | 351.35] loss=1.63 avg=2.00\n",
            "[380 | 359.97] loss=1.76 avg=1.99\n",
            "[390 | 368.58] loss=1.57 avg=1.98\n",
            "[400 | 377.20] loss=1.49 avg=1.96\n",
            "======== SAMPLE 1 ========\n",
            " we started to get really comfortable trying to do something all of the time. Our mindset is that: \"How can I push this a little bit? It's hard enough on my side.\" <|endoftext|>\n",
            "<|startoftext|>I love when people ask us why we're not just building more. No need for a new building.<|endoftext|>\n",
            "<|startoftext|>The best way to really get inspired is to go out and do something. This is why I wrote A Lesson - Not to get rich or to marry someone you love, but to get…<|endoftext|>\n",
            "<|startoftext|>You don't have to start with nothing. You never will. Start with something, and it will start you down a path…<|endoftext|>\n",
            "<|startoftext|>I got what I wanted - an amazing office and the opportunity to become a world-class developer and a star…<|endoftext|>\n",
            "<|startoftext|>I think of people with very little and those with lots of, like an over-sized pool with its t… <|endoftext|>\n",
            "<|startoftext|>The most important decision you can make is whether you believe it or not. You never know how things will really go. <|endoftext|>\n",
            "<|startoftext|>WEEKLY DONATIONS: <|endoftext|>\n",
            "<|startoftext|>We are in a period in which the average annual pay of CEO and CFO is roughly twice that of a S… <|endoftext|>\n",
            "<|startoftext|>We have a problem when CEOs give way to CFOs, and then CFOs become CEO<|endoftext|>\n",
            "<|startoftext|>The truth is we have to do it all. But we also have to do it. If we do it all, we'll all be better off. <|endoftext|>\n",
            "<|startoftext|>What makes the greatest company in the world better is not who they are. What makes the greatest company in the world better is what they do.<|endoftext|>\n",
            "<|startoftext|>Our relationship with others starts from the foundation of who we are and the foundation of what we believe: the belief is… <|endoftext|>\n",
            "<|startoftext|>You can create a world where nothing changes. You can create a world where everything happens. You can create a world where no one cares. You can create a world<|endoftext|>\n",
            "<|startoftext|>How To Get What You Want <|endoftext|>\n",
            "<|startoftext|>Trust Is A Feeling<|endoftext|>\n",
            "<|startoftext|>It is amazing how quickly new ideas are born. It seems to be such an ephemeral concept.  What I like the most about life are… <|endoftext|>\n",
            "<|startoftext|>We can have a world in which people want to do what we do. But if you want to do the things you do, you'll… <|endoftext|>\n",
            "<|startoftext|>Your Value <|endoftext|>\n",
            "<|startoftext|>It is so great to be able to take a life changing decision. I couldn't have imagined how amazing it would feel to finally choose to… <|endoftext|>\n",
            "<|startoftext|>If you want a life full of love<|endoftext|>\n",
            "<|startoftext|>How To Be Happier <|endoftext|>\n",
            "<|startoftext|>To all the CEOs and CFOs in your networks today<|endoftext|>\n",
            "<|startoftext|>Be Careful<|endoftext|>\n",
            "<|startoftext|>You can't be everything to everyone. The goal should not be to have as much power as possible<|endoftext|>\n",
            "<|startoftext|>So many people confuse success with status. The truth is that you will have more power if you do than what you... <|endoftext|>\n",
            "<|startoftext|>The most valuable lesson I can teach people<|endoftext|>\n",
            "<|startoftext|>If we are truly concerned with the world we will often do things that we find morally wrong. So if we do those things<|endoftext|>\n",
            "<|startoftext|>An excellent manager is not always a great manager<|endoftext|>\n",
            "<|startoftext|>A good idea is often worth many thousands<|endoftext|\n",
            "\n",
            "[410 | 406.34] loss=0.90 avg=1.93\n",
            "[420 | 414.96] loss=0.80 avg=1.90\n",
            "[430 | 423.58] loss=1.92 avg=1.90\n",
            "[440 | 432.19] loss=0.88 avg=1.87\n",
            "[450 | 440.81] loss=1.61 avg=1.86\n",
            "[460 | 449.43] loss=1.54 avg=1.85\n",
            "[470 | 458.05] loss=1.45 avg=1.84\n",
            "[480 | 466.67] loss=2.00 avg=1.85\n",
            "[490 | 475.29] loss=2.12 avg=1.85\n",
            "[500 | 483.91] loss=1.48 avg=1.84\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 499.47] loss=0.91 avg=1.82\n",
            "[520 | 508.10] loss=1.30 avg=1.81\n",
            "[530 | 516.72] loss=1.69 avg=1.81\n",
            "[540 | 525.34] loss=1.45 avg=1.80\n",
            "[550 | 533.96] loss=1.88 avg=1.80\n",
            "[560 | 542.58] loss=1.70 avg=1.80\n",
            "[570 | 551.22] loss=1.79 avg=1.80\n",
            "[580 | 559.85] loss=1.94 avg=1.80\n",
            "[590 | 568.47] loss=2.27 avg=1.81\n",
            "[600 | 577.09] loss=0.95 avg=1.79\n",
            "======== SAMPLE 1 ========\n",
            " <|endoftext|>\n",
            "<|startoftext|>joshhurtworton 👌<|endoftext|>\n",
            "<|startoftext|>joshhurtworton My wife doesn't understand why people who don't work in tech don't get startup investments:<|endoftext|>\n",
            "<|startoftext|>Craziest email ever: \"There is no 'work' and there is no 'work' and there's no Work.\"<|endoftext|>\n",
            "<|startoftext|>I love the \"work hard for something you want.\"<|endoftext|>\n",
            "<|startoftext|>RT paultoo: \"It's nice to try new things but you also have to try them very hard.\")\" - Bill Gates<|endoftext|>\n",
            "<|startoftext|>RT paultoo: \"It's nice to try new things but you also have to try them very hard.\")\" - Bill Gates\" - Bill Gates<|endoftext|>\n",
            "<|startoftext|>It would be hard for me to have been more wrong about when AI was going to be revolutionary and what it was capable of doing. Today<|endoftext|>\n",
            "<|startoftext|>RT paultoo: \"I hope and believe it will one day change the course of our history\" - Bill Gates<|endoftext|>\n",
            "<|startoftext|>(And I absolutely do not think it will).<|endoftext|>\n",
            "<|startoftext|>One of the saddest truths of life. One of the saddest things to observe. -Bill Gates<|endoftext|>\n",
            "<|startoftext|>paultoo actually delivered on all three promises he made - you get one*<|endoftext|>\n",
            "<|startoftext|>On the day the press was allowed on the third floor of the Carter Center<|endoftext|>\n",
            "<|startoftext|>Great book by lizzyholic :- ))<|endoftext|>\n",
            "<|startoftext|>I've been a big fan for years of lizzyholic's work on Change.org<|endoftext|>\n",
            "<|startoftext|>I'm excited about this! lizzyholic has done some amazing work over the last 4 years and we are beyond excited about her new deal with Change!<|endoftext|>\n",
            "<|startoftext|>Just received this from ryanbtwang that means a lot. He is definitely one of my fave authors right now. <|endoftext|>\n",
            "<|startoftext|>Love this! Love that! Thanks for the kind words! Keep it up! <|endoftext|>\n",
            "<|startoftext|>Another awesome little excerpt from the book: <|endoftext|>\n",
            "<|startoftext|>You can get one-on-one with Steve Jobs by listening to iTunes or Google Play. You can also go to one of the many Apple Stores<|endoftext|>\n",
            "<|startoftext|>The current record-holder for least reads Twitter is the average college student.  A great way to build community.<|endoftext|>\n",
            "<|startoftext|>How to Get a Company to Give Back:  Use 5 tips from one of my favorite <|endoftext|>\n",
            "<|startoftext|>The most productive conversations are in the back and forth between two and 10 people who understand something or have talked about it<|endoftext|>\n",
            "<|startoftext|>It doesn't matter when you start<|endoftext|>\n",
            "<|startoftext|>I'm on a mission to change my mindset about when to start.  It's so much more helpful when I say when than when I do.<|endoftext|>\n",
            "<|startoftext|>This is by far one of my most requested read of the year! <|endoftext|>\n",
            "<|startoftext|>The most interesting and important lesson I learned from having been through hell & back at least 10 times is that you shouldn't try to force people into your life when you're not prepared for them<|endoftext|>\n",
            "<|startoftext|>There are currently 8 billion homes on the planet.  It would take an extremely huge population explosion for the climate to handle<|endoftext|>\n",
            "<|startoftext|>The first step to getting over the death of the family is having a plan for them to travel with.<|endoftext|>\n",
            "<|startoftext|>I am super excited about this! I can\n",
            "\n",
            "[610 | 606.25] loss=1.63 avg=1.79\n",
            "[620 | 614.86] loss=1.07 avg=1.77\n",
            "[630 | 623.54] loss=1.00 avg=1.76\n",
            "[640 | 632.16] loss=0.72 avg=1.73\n",
            "[650 | 640.78] loss=0.91 avg=1.72\n",
            "[660 | 649.39] loss=1.01 avg=1.70\n",
            "[670 | 658.00] loss=0.83 avg=1.68\n",
            "[680 | 666.62] loss=0.83 avg=1.67\n",
            "[690 | 675.24] loss=0.77 avg=1.65\n",
            "[700 | 683.85] loss=1.28 avg=1.64\n",
            "[710 | 692.47] loss=1.25 avg=1.63\n",
            "[720 | 701.08] loss=1.25 avg=1.63\n",
            "[730 | 709.70] loss=2.59 avg=1.65\n",
            "[740 | 718.30] loss=1.83 avg=1.65\n",
            "[750 | 726.92] loss=1.97 avg=1.65\n",
            "[760 | 735.52] loss=0.96 avg=1.64\n",
            "[770 | 744.13] loss=1.38 avg=1.64\n",
            "[780 | 752.74] loss=1.56 avg=1.64\n",
            "[790 | 761.35] loss=0.99 avg=1.62\n",
            "[800 | 769.97] loss=1.05 avg=1.61\n",
            "======== SAMPLE 1 ========\n",
            "|>SiddhantT1 That doesn't mean they aren’t important<|endoftext|>\n",
            "<|startoftext|>masonjw Seemingly every year. Just look at your friends' faces.<|endoftext|>\n",
            "<|startoftext|>masonjw Also<|endoftext|>\n",
            "<|startoftext|>masonjw Seems far more likely to be a false positive.<|endoftext|>\n",
            "<|startoftext|>masonjw <|endoftext|>\n",
            "<|startoftext|>prahalad rsaandj vithalhj Enough. Just don’t freak out when people like you say… <|endoftext|>\n",
            "<|startoftext|>ryanjtsukka jimkwik That gets at the fundamental problem that I have with this whole thing.<|endoftext|>\n",
            "<|startoftext|>johnnygraham 👏<|endoftext|>\n",
            "<|startoftext|>jaltma_ \"All you have to do is sit still and you'll get t…<|endoftext|>\n",
            "<|startoftext|>jason_soedelswich There is a huge<|endoftext|>\n",
            "<|startoftext|>KirstyChirimire 🙏  <|endoftext|>\n",
            "<|startoftext|>rshrva How do they know? They aren’t like normal people<|endoftext|>\n",
            "<|startoftext|>Hearing it as clearly as humanly possible is the hard part. In terms of<|endoftext|>\n",
            "<|startoftext|>RohitVohra 👌<|endoftext|>\n",
            "<|startoftext|>RohitVohra I think I said this to myself.<|endoftext|>\n",
            "<|startoftext|>mikekarnj It’s a non-issue in my view; it’s about interpretation. The problem is that I think<|endoftext|>\n",
            "<|startoftext|>datarade Like I’m saying<|endoftext|>\n",
            "<|startoftext|>datarade If anything<|endoftext|>\n",
            "<|startoftext|>vizioh Yes<|endoftext|>\n",
            "<|startoftext|>AeonMinista I think it’s fair.<|endoftext|>\n",
            "<|startoftext|>mollykarlthefog I don’t know if this is a true conspiracy theory; if so<|endoftext|>\n",
            "<|startoftext|>EvanJEngelson jockowillink It’s not my website and it wasn’t my intent. However, for some reason it just…<|endoftext|>\n",
            "<|startoftext|>jockowillink People who post content on my site and then link it to friends… <|endoftext|>\n",
            "<|startoftext|>jockowillink I’m not here to engage in any discussion; there’s no need anyway. However, if people want to discuss this then I am happy to engage. I’m not here… <|endoftext|>\n",
            "<|startoftext|>rutvahn  <|endoftext|>\n",
            "<|startoftext|>jocksandbox Maybe it’s easier with a computer monitor?<|endoftext|>\n",
            "<|startoftext|>RT zenonix: If you have to make a choice between looking at your wife and your child…<|endoftext|>\n",
            "<|startoftext|>anahadoconnor Anahad. That doesn’t mean they aren’t important.<|endoftext|>\n",
            "<|startoftext|>snowwhitebui It’s the first draft; it’ll have to be validated by other writers before it can make it into the final version.<|endoftext|>\n",
            "<|startoftext|>Anahad<|endoftext|>\n",
            "<|startoftext|>anahadoconnor It’s just words and ideas; some common sense in there.<|endoftext|>\n",
            "<|startoftext|>snowwhitebui Anahad the first draft just says that it’s satire. The last one says Trump will… <|endoftext|>\n",
            "<|startoftext|>anahad The first draft\n",
            "\n",
            "[810 | 798.70] loss=1.67 avg=1.61\n",
            "[820 | 807.31] loss=1.53 avg=1.61\n",
            "[830 | 815.93] loss=0.76 avg=1.60\n",
            "[840 | 824.54] loss=1.76 avg=1.60\n",
            "[850 | 833.16] loss=2.10 avg=1.61\n",
            "[860 | 841.77] loss=0.84 avg=1.60\n",
            "[870 | 850.38] loss=0.77 avg=1.58\n",
            "[880 | 859.02] loss=0.43 avg=1.56\n",
            "[890 | 867.63] loss=0.85 avg=1.55\n",
            "[900 | 876.24] loss=1.30 avg=1.55\n",
            "[910 | 884.84] loss=1.05 avg=1.54\n",
            "[920 | 893.45] loss=1.18 avg=1.53\n",
            "[930 | 902.06] loss=1.40 avg=1.53\n",
            "[940 | 910.67] loss=1.22 avg=1.52\n",
            "[950 | 919.28] loss=1.06 avg=1.52\n",
            "[960 | 927.91] loss=0.51 avg=1.50\n",
            "[970 | 936.57] loss=1.19 avg=1.50\n",
            "[980 | 945.18] loss=0.65 avg=1.48\n",
            "[990 | 953.79] loss=0.53 avg=1.47\n",
            "[1000 | 962.40] loss=0.41 avg=1.45\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Db_X7rg-RQ4",
        "outputId": "32924f71-9859-400c-d41b-752c16f83047"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4nPGjx4lCUY"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o3LsB0OqAOL"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')#loading model from google drive"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ_aaimo-NzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a2f232-34fa-47db-9987-9c9aacbaacfd"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWwDiMjI-PZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52e4f04-ea8a-48eb-8ffd-b84d9a8425fe"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=100,\n",
        "              temperature=0.5,\n",
        "              run_name='run1',\n",
        "              prefix=\"<|startoftext|>\",\n",
        "              truncate=\"<|endoftext|>\",\n",
        "              include_prefix=False,\n",
        "              nsamples=20,\n",
        "              batch_size=20)\n",
        "            "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We’re not a team. A team is a group of people that work together to achieve a common goal. A team is a group of people that work together to achieve a common goal\n",
            "====================\n",
            "The number one predictor of whether or not a startup will succeed: rate of iteration.\n",
            "====================\n",
            "paulg it's a big world out there. and i hope you are right :)\n",
            "====================\n",
            "I'm speaking at the Ritz in NYC. 7pm. RSVPs are preferred but available. Free event. RSVPs are only for those who RSVP and are not to be used for resale\n",
            "====================\n",
            "The only thing more amazing than a genius is a genius who can figure out how to figure out what a genius can figure out\n",
            "====================\n",
            "If you are in NYC on Jan 6, please join me to launch a new movement: #IamAus! We stand with you at every step. #NYCC #startwithwhy\n",
            "====================\n",
            "This is the most amazing tech demonstration i've seen in a long time!  \n",
            "====================\n",
            "If you don't know where you're going\n",
            "====================\n",
            "It's better to disappoint with the truth than please with a lie.\n",
            "====================\n",
            "Sitting in my favorite Monet painting.  \n",
            "====================\n",
            "The best founders are also the most humble. They work to make their product better\n",
            "====================\n",
            "RT paulg: Can you imagine if the media covered the G20 in the US and the UK as a single event? It would have been the equivalent of the Nazi invasion of the US on 3Mpls. \n",
            "====================\n",
            "jaltma the new normal\n",
            "====================\n",
            "austinmorgan yt0321 I’m judging. I’m not a judge. 😂\n",
            "====================\n",
            "I think I am in the extreme minority here\n",
            "====================\n",
            "We’re not going to stop fighting for what we believe in. We’re going to stop fighting for the cause. We’re going to stop fighting for the people that we meet.We’re going to meet the people that inspire us\n",
            "====================\n",
            "RT paulg: There's a difference beween an entrepreneur and; small biz owner. Small biz owners own small businesses.\n",
            "====================\n",
            "When a company's identity is in question\n",
            "====================\n",
            "The only way to find out if it will work is simple - do it.\n",
            "====================\n",
            "Welcome\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEIVtdmImb0R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-6oF3-XzIL8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}